{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of custom_id_to_content: 360\n",
      "size of custom_id_to_content: 360\n",
      "size of custom_id_to_content: 360\n",
      "size of custom_id_to_content_original: 360\n",
      "Missing files: {'Acknowledgement': set()}\n",
      "size of custom_id_to_content: 408\n",
      "size of custom_id_to_content: 408\n",
      "size of custom_id_to_content: 408\n",
      "size of custom_id_to_content_original: 408\n",
      "Missing files: {'Acknowledgement': set(), 'Subdermatoglyphic': set()}\n",
      "size of custom_id_to_content: 480\n",
      "size of custom_id_to_content: 480\n",
      "size of custom_id_to_content: 480\n",
      "size of custom_id_to_content_original: 480\n",
      "Missing files: {'Acknowledgement': set(), 'Subdermatoglyphic': set(), 'tHyUiKaRbNqWeOpXcZvM': set()}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the words and their corresponding JSONL file paths\n",
    "WORDs = [\n",
    "    \"Acknowledgement\",\n",
    "    \"Subdermatoglyphic\",\n",
    "    \"tHyUiKaRbNqWeOpXcZvM\",\n",
    "]\n",
    "GPT4Outputs = [\n",
    "    \"./jsonl/Acknowledgement-batch_XbhrSOcSB5EuAalvaf6pPnwp_output.jsonl\",\n",
    "    \"./jsonl/Subdermatoglyphic-batch_KsEDCtqcuiLUd0fctyVDLeuJ_output.jsonl\",\n",
    "    \"./jsonl/tHyUiKaRbNqWeOpXcZvM-batch_zSapvpcg51piGdd3wDSRqoGH_output.jsonl\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "all_data_frames = []\n",
    "missing_files = {}\n",
    "\n",
    "# Loop through each word and its corresponding file\n",
    "for index, WORD in enumerate(WORDs):\n",
    "    file_path = GPT4Outputs[index]\n",
    "    gt_data = pd.read_json(f\"./images/{WORD}/configurations.json\")\n",
    "    custom_id_to_content = {}\n",
    "\n",
    "    gt_data[\"fnames\"] = gt_data[\"image_path\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "    expected_files = set(list(gt_data[\"fnames\"]))\n",
    "\n",
    "    # Read the JSONL file and extract data\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            custom_id = json_obj.get(\"custom_id\")\n",
    "            message_content = json_obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\n",
    "                \"content\"\n",
    "            ]\n",
    "            if custom_id:\n",
    "                custom_id_to_content[custom_id] = message_content\n",
    "            else:\n",
    "                print(f\"WARNING: Custom id is None for {line}\")\n",
    "\n",
    "    print(f\"size of custom_id_to_content: {len(custom_id_to_content)}\")\n",
    "\n",
    "    custom_id_to_content_original = custom_id_to_content.copy()\n",
    "    custom_id_to_content_original = {\n",
    "        key.split(\"uid__\")[-1]: value\n",
    "        for key, value in custom_id_to_content_original.items()\n",
    "    }\n",
    "    # Process the extracted data\n",
    "    custom_id_to_content = {\n",
    "        key.split(\"uid__\")[-1]: value.split('\"')[1] if '\"' in value else value\n",
    "        for key, value in custom_id_to_content.items()\n",
    "    }\n",
    "    custom_id_to_content = {\n",
    "        key: value.lower().replace(\".\", \"\").strip()\n",
    "        for key, value in custom_id_to_content.items()\n",
    "    }\n",
    "\n",
    "    print(f\"size of custom_id_to_content: {len(custom_id_to_content)}\")\n",
    "\n",
    "    custom_id_to_content = {\n",
    "        key: value for key, value in custom_id_to_content.items() if len(value) == 1\n",
    "    }\n",
    "\n",
    "    print(f\"size of custom_id_to_content: {len(custom_id_to_content)}\")\n",
    "    print(\n",
    "        f\"size of custom_id_to_content_original: {len(custom_id_to_content_original)}\"\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame and merge\n",
    "    custom_id_df = pd.DataFrame(\n",
    "        list(custom_id_to_content.items()), columns=[\"image_path\", \"predicted\"]\n",
    "    )\n",
    "    combined_data = pd.merge(gt_data, custom_id_df, on=\"image_path\", how=\"inner\")\n",
    "    combined_data[\"gt\"] = combined_data.apply(\n",
    "        lambda row: row[\"word\"][row[\"circle_index\"]].lower(), axis=1\n",
    "    )\n",
    "    combined_data[\"word_label\"] = WORD  # Add a column to identify the word\n",
    "\n",
    "    # add custom_id_to_content_original as model-output-raw\n",
    "    combined_data[\"model-output-raw\"] = combined_data[\"image_path\"].map(\n",
    "        custom_id_to_content_original\n",
    "    )\n",
    "\n",
    "    # Append to the list\n",
    "    all_data_frames.append(combined_data)\n",
    "    # check for missing files\n",
    "    combined_data[\"fname\"] = combined_data[\"image_path\"].apply(\n",
    "        lambda x: x.split(\"/\")[-1]\n",
    "    )\n",
    "    missing_files[WORD] = set(expected_files) - set(list(combined_data[\"fnames\"]))\n",
    "    print(f\"Missing files: {missing_files}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_data_frame = pd.concat(all_data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame[\"Model\"] = [\"GPT-4o\"] * len(final_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame.to_pickle(\"./data/gpt-4o.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model   word                \n",
       "GPT-4o  Acknowledgement         360\n",
       "        Subdermatoglyphic       408\n",
       "        tHyUiKaRbNqWeOpXcZvM    480\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count per model and prompt\n",
    "final_data_frame.groupby([\"Model\", \"word\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defaulttorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
