{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the JSONL file\n",
    "WORDs = [\n",
    "    \"Acknowledgement\",\n",
    "    \"Subdermatoglyphic\",\n",
    "    \"tHyUiKaRbNqWeOpXcZvM\",\n",
    "]\n",
    "\n",
    "index = 1\n",
    "WORD = WORDs[index]\n",
    "\n",
    "gt_data = pd.read_json(f\"./images_second_prompt//{WORD}/configurations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplace ./images/ with ./images_second_prompt/\n",
    "gt_data[\"image_path\"] = gt_data[\"image_path\"].apply(\n",
    "    lambda x: x.replace(\"./images/\", \"./images_second_prompt/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_image_0a5fd2d1-d0ad-490d-a4d4-a01955a8de8c\n",
    "\n",
    "gt_data[\"model-output-file\"] = gt_data[\"image_path\"].apply(\n",
    "    lambda x: x.replace(\".png\", \"\") + \"-claude-3-sonnet-20240229-output.md\"\n",
    ")\n",
    "\n",
    "gt_data[\"model-output-raw\"] = gt_data[\"model-output-file\"].apply(\n",
    "    lambda x: (open(x, \"r\").read() if os.path.exists(os.path.join(x)) else None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing sonnet output\n",
    "gt_data = gt_data.dropna(subset=[\"model-output-raw\"])\n",
    "gt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_marked_text(text):\n",
    "    import re\n",
    "\n",
    "    # Check if the description explicitly states that no letter is being circled\n",
    "    no_circled_letter_patterns = [\n",
    "        \"no letter being circled\",\n",
    "        \"no individual letter\",\n",
    "        \"no circles or other annotations\",\n",
    "        \"no circled letter\",\n",
    "        \"no letters being circled\",\n",
    "        \"no character being highlighted\",\n",
    "        \"no red oval or any other highlighting\",\n",
    "        \"no red oval highlighting any character\",\n",
    "        \"no red oval or any highlighted character\",\n",
    "        \"no red oval or highlighting\",\n",
    "        \"no character highlighted with a red oval\",\n",
    "        \"the image does not contain any characters highlighted with a red oval\",\n",
    "        \"the image does not contain any red oval highlighting a specific character\",\n",
    "        \"there is no red oval or any character being highlighted\",\n",
    "        \"there is no character highlighted with a red oval in this image\",\n",
    "        \"there is no image provided\",\n",
    "        \"the image simply shows\",\n",
    "        \"the text appears to be a sequence of mixed uppercase and lowercase letters without any particular emphasis or highlighting\",\n",
    "        \"the image does not contain any red oval or highlighted character\",\n",
    "        \"the image simply shows a string of seemingly random capitalized letters\",\n",
    "        \"no red oval or any highlighting\",\n",
    "        \"the image does not contain any red oval or highlighted character\",\n",
    "        \"the image simply shows a string of seemingly random capitalized letters\",\n",
    "        \"there is no red oval or any highlighting in the provided image\",\n",
    "        \"the image shows a string of uppercase letters displayed against a plain white background\",\n",
    "        \"no red oval or any highlighting\",\n",
    "        \"the image does not contain any red oval or highlighted character\",\n",
    "        \"the image simply shows a string of seemingly random capitalized letters\",\n",
    "        \"there is no red oval or any highlighting in the provided image\",\n",
    "        \"the image shows a string of uppercase letters displayed against a plain white background\",\n",
    "    ]\n",
    "    if any(phrase in text.lower() for phrase in no_circled_letter_patterns):\n",
    "        return \"none\"\n",
    "\n",
    "    # Use regular expressions to find single characters or explicitly mentioned letters or numbers\n",
    "    patterns = [\n",
    "        r\"the (letter|number) being circled in the [^\\.]* is ['\\\"]?([a-zA-Z0-9])['\\\"]?\",\n",
    "        r\"['\\\"]([a-zA-Z0-9])['\\\"]\",\n",
    "        r\"the character highlighted with a red oval in the word ['\\\"]?[^'\\\"]*['\\\"]? is the (lowercase|uppercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the word ['\\\"]?[^'\\\"]*['\\\"]? is the (lowercase|uppercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the (image|word) is the (number|numeral) ['\\\"]?([0-9])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the provided image is the (number|numeral) ['\\\"]?([0-9])['\\\"]? in the word ['\\\"]?[^'\\\"]*['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the (given text|string|image) is the (uppercase|lowercase)? ?(letter|number) ['\\\"]?([a-zA-Z0-9])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the (given text|string|image) is the (letter|number) ['\\\"]?([a-zA-Z0-9])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval is the (uppercase|lowercase)? ?(letter|number) ['\\\"]?([a-zA-Z0-9])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the string of letters ['\\\"]?[^'\\\"]*['\\\"]? is the letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the given text string is ['\\\"]?([^'\\\"]+)['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the (given text|string|image) ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the (given text|string|image) ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the text string ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the (given text|string|image) ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the (given text|string|image) ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character being highlighted with a red oval in the text string ['\\\"]?([^'\\\"]+)['\\\"]? is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the given text ['\\\"]?([^'\\\"]+)['\\\"]? is the letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "        r\"the character highlighted with a red oval in the given text is the (uppercase|lowercase)? ?letter ['\\\"]?([a-zA-Z])['\\\"]?\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            # Extract the last group which should be the character or substring\n",
    "            result = match.group(match.lastindex).lower()\n",
    "            # If the result is a longer substring, handle it appropriately\n",
    "            if len(result) > 1 and not result.isdigit():\n",
    "                # Handle specific cases like \"We\" or \"ZvM\"\n",
    "                if result in [\"we\", \"zvm\"]:\n",
    "                    return result\n",
    "                else:\n",
    "                    continue\n",
    "            return result  # Return the matched letter or number in lowercase\n",
    "\n",
    "    return \"marker_not_found\" + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data[\"predicted\"] = gt_data[\"model-output-raw\"].apply(extract_marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full column and row\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "gt_data[\"predicted\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = gt_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"gt\"] = cleaned_data.apply(\n",
    "    lambda row: row[\"word\"][row[\"circle_index\"]].lower(), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"is_prediction_correct\"] = cleaned_data[\"gt\"] == cleaned_data[\"predicted\"]\n",
    "# get accuracy\n",
    "accuracy = cleaned_data[\"is_prediction_correct\"].mean()\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = cleaned_data[cleaned_data[\"is_prediction_correct\"] == False]\n",
    "common_errors = (\n",
    "    errors.groupby([\"predicted\", \"gt\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n",
    "print(common_errors.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the matplotlib figure with a more professional color palette and layout\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(18, 12))\n",
    "fig.suptitle(f\"Detailed Analysis of Model Predictions -- {WORD}\", fontsize=16)\n",
    "\n",
    "# Customize the color palette\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# Plot Accuracy by Font Path\n",
    "sns.barplot(\n",
    "    ax=axes[0, 0],\n",
    "    x=\"is_prediction_correct\",\n",
    "    y=\"font_path\",\n",
    "    data=cleaned_data,\n",
    "    estimator=lambda x: x.mean(),\n",
    "    palette=\"Blues_d\",\n",
    ")\n",
    "axes[0, 0].set_title(\"Accuracy by Font Path\")\n",
    "axes[0, 0].set_xlabel(\"Accuracy\")\n",
    "axes[0, 0].set_ylabel(\"Font Path\")\n",
    "\n",
    "# Plot Accuracy by Circle Index\n",
    "sns.barplot(\n",
    "    ax=axes[0, 1],\n",
    "    x=\"circle_index\",\n",
    "    y=\"is_prediction_correct\",\n",
    "    data=cleaned_data,\n",
    "    estimator=lambda x: x.mean(),\n",
    "    palette=\"Greens_d\",\n",
    ")\n",
    "axes[0, 1].set_title(\"Accuracy by Circle Index\")\n",
    "axes[0, 1].set_xlabel(\"Circle Index\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\")\n",
    "# Set x-axis labels to characters from the word\n",
    "axes[0, 1].set_xticklabels(list(\"Subdermatoglyphic\"))\n",
    "\n",
    "\n",
    "# Plot Distribution of Incorrect Predictions\n",
    "sns.countplot(\n",
    "    ax=axes[1, 0],\n",
    "    x=\"predicted\",\n",
    "    data=errors,\n",
    "    order=errors[\"predicted\"].value_counts().index,\n",
    "    palette=\"Reds_d\",\n",
    ")\n",
    "axes[1, 0].set_title(\"Distribution of Incorrect Predictions\")\n",
    "axes[1, 0].set_xlabel(\"Predicted Characters\")\n",
    "axes[1, 0].set_ylabel(\"Count\")\n",
    "\n",
    "# Plot Distribution of Ground Truth for Incorrect Predictions\n",
    "sns.countplot(\n",
    "    ax=axes[1, 1],\n",
    "    x=\"gt\",\n",
    "    data=errors,\n",
    "    order=errors[\"gt\"].value_counts().index,\n",
    "    palette=\"Purples_d\",\n",
    ")\n",
    "axes[1, 1].set_title(\"Distribution of Ground Truth for Incorrect Predictions\")\n",
    "axes[1, 1].set_xlabel(\"Ground Truth Characters\")\n",
    "axes[1, 1].set_ylabel(\"Count\")\n",
    "\n",
    "# Plot Accuracy by Thickness\n",
    "sns.lineplot(\n",
    "    ax=axes[2, 0],\n",
    "    x=\"thickness\",\n",
    "    y=\"is_prediction_correct\",\n",
    "    data=cleaned_data,\n",
    "    estimator=lambda x: x.mean(),\n",
    "    marker=\"o\",\n",
    "    color=\"deepskyblue\",\n",
    ")\n",
    "axes[2, 0].set_title(\"Accuracy by Thickness\")\n",
    "axes[2, 0].set_xlabel(\"Thickness\")\n",
    "axes[2, 0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust subplots to fit into figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract ground truth and predictions\n",
    "ground_truth = cleaned_data[\"gt\"]\n",
    "predictions = cleaned_data[\"predicted\"]\n",
    "\n",
    "# Define the order of labels based on the word \"Acknowledgement\" and any extra characters\n",
    "desired_order = list(\n",
    "    \"Acknowledgement\"\n",
    ")  # Ensure it's in lowercase if your data is in lowercase\n",
    "all_labels = np.unique(np.concatenate((ground_truth, predictions)))\n",
    "extra_labels = [label for label in all_labels if label not in desired_order]\n",
    "final_labels = desired_order + extra_labels\n",
    "\n",
    "# Create the confusion matrix with the specified label order\n",
    "conf_matrix = confusion_matrix(ground_truth, predictions, labels=final_labels)\n",
    "\n",
    "# Plot the confusion matrix with a more professional appearance\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.set(font_scale=1.4)  # Increase font size for readability\n",
    "heatmap = sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=final_labels,\n",
    "    yticklabels=final_labels,\n",
    "    cbar_kws={\"label\": \"Frequency\"},\n",
    ")\n",
    "plt.title(f\"Confusion Matrix -- {WORD}\", fontsize=18, fontweight=\"bold\")\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the words\n",
    "WORDs = [\n",
    "    \"Acknowledgement\",\n",
    "    \"Subdermatoglyphic\",\n",
    "    \"tHyUiKaRbNqWeOpXcZvM\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "all_data_frames = []\n",
    "\n",
    "# Loop through each word\n",
    "for WORD in WORDs:\n",
    "    gt_data = pd.read_json(f\"./images/{WORD}/configurations.json\")\n",
    "    # remplace ./images/ with ./images_second_prompt/\n",
    "    gt_data[\"image_path\"] = gt_data[\"image_path\"].apply(\n",
    "        lambda x: x.replace(\"./images/\", \"./images_second_prompt/\")\n",
    "    )\n",
    "    # Generate model output file paths and read the content if the file exists\n",
    "    gt_data[\"model-output-file\"] = gt_data[\"image_path\"].apply(\n",
    "        lambda x: x.replace(\".png\", \"\") + \"-claude-3-sonnet-20240229-output.md\"\n",
    "    )\n",
    "    gt_data[\"model-output-raw\"] = gt_data[\"model-output-file\"].apply(\n",
    "        lambda x: (open(x, \"r\").read() if os.path.exists(x) else None)\n",
    "    )\n",
    "\n",
    "    # Drop rows with missing sonnet output\n",
    "    gt_data = gt_data.dropna(subset=[\"model-output-raw\"])\n",
    "\n",
    "    gt_data[\"predicted\"] = gt_data[\"model-output-raw\"].apply(extract_marked_text)\n",
    "    print(gt_data[\"predicted\"].value_counts())\n",
    "    # Calculate ground truth and correctness\n",
    "    gt_data[\"gt\"] = gt_data.apply(\n",
    "        lambda row: row[\"word\"][row[\"circle_index\"]].lower(), axis=1\n",
    "    )\n",
    "    gt_data[\"is_prediction_correct\"] = gt_data[\"gt\"] == gt_data[\"predicted\"]\n",
    "    gt_data[\"word_label\"] = WORD  # Add a column to identify the word\n",
    "\n",
    "    # Append to the list\n",
    "    all_data_frames.append(gt_data)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_data_frame = pd.concat(all_data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame[\"Model\"] = [\"Sonnet\"] * len(final_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame.to_pickle(\"./data/Sonnet-2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defaulttorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
